\documentclass{report}
\usepackage[cp1250]{inputenc}
\usepackage[slovene]{babel}

\begin{document}

\title{{\bf Financial Econometrics} \\[3mm]
Homework assigment}
%\subtitle{Analiza indeksov izgubljene prtljage}
\author{Zala Jamšek\\ 27122040}

\SweaveOpts{concordance=TRUE}
\maketitle
\newpage

\newpage

%%%-----PROBLEM 1-------

\title{\bf Problem 1}
\\
MA(1) process:$$R_t = \epsilon_t + 0.25 \epsilon_{t-1}$$

$\epsilon_t$ is white noise therefore $\epsilon_t \sim N(0, \delta_\epsilon)$ \\
$E[\epsilon_t] = 0$, $Var(\epsilon_t) = \delta_\epsilon^2$, $\delta_\epsilon = 0.01$ and $E[\epsilon_t, \epsilon_s] = 0$  $\forall s \neq t$
\\[3mm]

{\bf 1.}\\[1mm]
{\it lag-1 autocorrelation:}\\[1mm]
$$E[R_t] = E[\epsilon_t + 0.25 \epsilon_{t-1}] = 0$$
\begin{eqnarray*}
Var(R_t) &=& Var(\epsilon_t + 0.25 \epsilon_{t-1}) = Var(\epsilon_t) + 0.25^2 Var(\epsilon_{t-1}) \\
&=& 0.01^2 (1+0.25^2) = 0.00010625 
\end{eqnarray*}

\begin{eqnarray*}
Cov(R_t, R_{t-1})&=& E[(R_t - E(R_t))(R_{t-1} - E(R_{t-1}))] = E[R_t R_{t-1}]\\
&=&E[(\epsilon_t+0.25 \epsilon_{t-1})(\epsilon_{t-1}+0.25 \epsilon_{t-2})] \\
&=& E[\epsilon_t \epsilon_{t-1}] + 0.25 E[\epsilon_t \epsilon_{t-2}] + 0.25 E[\epsilon_{t-1} \epsilon_{t-1}] + 0.25^2 E[\epsilon_t \epsilon_{t-2}]\\
&=& 0.25 E[\epsilon_t ^2] = 0.25 * 0.01^2 = 0.000025
\end{eqnarray*}

\begin{eqnarray*}
corr (R_t, R_{t-1}) = \frac{cov((R_t, R_{t-1}))}{\sqrt{Var(R_t)}\sqrt{Var(R_{t-1})}}=\frac{0.025}{0.10625} =0.2353 
\end{eqnarray*}

{\it lag-2 autocorrelation}: \\[1mm]
\begin{eqnarray*}
Cov(R_t, R_{t-2})&=& E[(R_t - E(R_t))(R_{t-2} - E(R_{t-2}))] = E[R_t R_{t-2}]\\
&=&E[(\epsilon_t+0.25 \epsilon_{t-1})(\epsilon_{t-2}+0.25 \epsilon_{t-3})] \\
&=& E[\epsilon_t \epsilon_{t-2}] + 0.25 E[\epsilon_t \epsilon_{t-3}] + 0.25 E[\epsilon_{t-1} \epsilon_{t-2}] + 0.25^2 E[\epsilon_t \epsilon_{t-2}]\\
&=& 0
\end{eqnarray*}
\begin{eqnarray*}
corr (R_t, R_{t-2}) = \frac{cov((R_t, R_{t-2}))}{\sqrt{Var(R_t)}\sqrt{Var(R_{t-2})}}=0 
\end{eqnarray*}

{\bf 2.}\\[3mm]

{\it 1-month ahead forecast}:
\begin{eqnarray*}
\hat{R}_{100}(1)&=& E[\epsilon_{101}|\epsilon_{100},\epsilon_{99},...\epsilon_{0}]=E[\epsilon_{101}+0.25 \epsilon_{100}|\epsilon_{100} = 0.01] \\
&=& 0.25*0.01 = 0.0025
\end{eqnarray*}

{\it Forecast error}: $e_{100}(1) = \epsilon_{101}$
$$Var(e_{100}(1))= \sigma_{\epsilon}^2=0.0001$$

\\[2mm]

{\it 2-month ahead forecast:}
\begin{eqnarray*}
\hat{R}_{100}(2)= E[\epsilon_{102}|\epsilon_{100},\epsilon_{99},...\epsilon_{0}]=E[\epsilon_{102}+0.25 \epsilon_{101}|\epsilon_{100} = 0.01] = 0
\end{eqnarray*}

{\it Forecast error}:$e_{100}(2) = \epsilon_{102} + 0.25 \epsilon_{101}$

$$Var(e_{100}(2))= (1 + 0.25^2) \sigma_{\epsilon}^2=0.00010625$$

{\bf 3.}\\ [1mm]
{\it standard error of forecast:}

$$se(1) = \sqrt{Var(e_{100}(1))} = 0.01$$
$$se(2) = \sqrt{Var(e_{100}(2))} = 0.0103$$

\clearpage

%%%-----PROBLEM 2-------

\title{\bf Problem 2}
\\[3mm]

AR(1) process: 
$$r_t = 0.01 + 0.5 r_{t-1} + \epsilon_t$ where $\epsilon_t \sim N(0, 0.03)$$

{\bf 1.}
\begin{eqnarray*}
E[r_t] &=& E[0.01 + 0.5 r_{t-1} + \epsilon_t]\\
&=& 0.01 + 0.5 E[0.01 + 0.5 r_{t-2} + \epsilon_{t-1}] \\
&=& 0.01 \frac{1}{1-0.5} = 0.02
\end{eqnarray*}

$$Var(r_t) = \frac{\sigma_{\epsilon}^2}{1-0.5^2} = \frac{0.009}{0.75}= 0.0012$$

{\bf 2.}\\
$r_{100} = -0.01$ and $r_{99} = 0.02$\\[1mm]

{\it 1-month forecast:}
\begin{eqnarray*}
\hat{r}_{100}(1) &=& E[r_{101}|r_{100}, r_{99}...r_{0}] = E[ 0.01 + 0.5 r_{100} + \epsilon_{101} |r_{100} = -0.01]\\
&=& 0.01 + 0.5*(-0.01) = 0.005
\end{eqnarray*}

{\it Forecast error}: $e_{100}(1) = \epsilon_{100} $
$$Var(e_{100}(1)) = \sigma_{\epsilon}^2 = 0.03$$

{\it 2-months forecast:}
\begin{eqnarray*}
\hat{r}_{100}(2) &=& E[r_{102}|r_{100}, r_{99}...r_{0}] = E[ 0.01 + 0.5 r_{101} + \epsilon_{101} |r_{100} = -0.01]\\
&=& E [0.01 + 0.5 (0.01 + 0.5 r_{100} + \epsilon_{101})+\epsilon_{102}|r_{100} = -0.01]\\
&=&0.01 +0.5(0.01 + 0.5*(-0.01)) =  0.0125
\end{eqnarray*}

{\it Forecast error} : $e_{100}(2) = 0.5 \epsilon_{101} + \epsilon_{102}$
$$Var(e_{100}(2)) = (0.5^2 + 1)\sigma_{\epsilon}^2 = 0.0375 $$

{\bf 3.}\\
{\it standard error of forecast:}
$$se(1) = \sqrt{Var(e_{100}(1))} = 0.1732$$
$$se(1) = \sqrt{Var(e_{100}(2))} =  0.1936$$

\clearpage
%%%-----PROBLEM 3-------

\title{\bf Problem 3}
\\[3mm]
{\bf 1.}\\[1mm]
The Akaike information criterion (AIC) is a measure of the relative quanlity of a statistival model and deals with the trade-off between goodness of fit of the model and the complexity of the model. AIC does not tell anything about the quality of the model in an absolute sence and does not proveide a test of a model in the sence of testing null hypothesis. 

AIC rewards goodnes of fit and includes penalty which is an increasing function of the number of estimated parameters which discourages overfitting. Thus AIC selects a model that fitts well but has a minimum number of parameters.

In a set of candidate models for the data, the model with the minimum AIC value is the preferred model. Hence the value of AIC for a given data set has no meaning and it only becomes interesting when it is compaired to the AIC of a series of models. If only poor models are considered, AIC will select the best of the poor models.

AIC for AR:
$$AIC (p) = ln(\hat{\sigma}^2) + \frac{2p}{T}$$

The first part measures the goodnes of fit. The higher the number of regressors, the lower ressiduals variance $\hat{sigma}^2$. The second part penalizes the number of regressors.\\[3mm]

{\bf 2.}\\

First we read the data and look at the time series of interest rates
<<fig= TRUE>>=
data <- read.table("C:/Users/Zali/Documents/Econometrics 2/yields.csv"
                     ,sep=",", header=TRUE)
yields <- ts(data[,2:4])
plot(yields, main = 'Time series treas3mo, treas2yr and treas10yr ')
treas3mo <- ts(data$treas3mo)
treas2yr <- ts(data$treas2yr)
treas10yr <- ts(data$treas10yr)
@

Now we define a function which plots $AIC(p)$ for $p = 1,.., p_{max}$.  For each p we estimate AR(p) model with the function ar that is already available in R and from there we get $\hat{\sigma}^2$ that is used in the $AIC$. 

<<fig = TRUE>>=
AIC <- function (data, p_max){
  aic <- c()
  for (p in 1:p_max){
    model <- ar(data, aic = FALSE, method = 'ols', order=p)
    sigma <- model$var.pred 
    aic_p <- log(sigma) + 2*p/(length(data)-p)
    aic <- c(aic, aic_p)
  }
  plot(1:p_max, aic)
  return(which(aic ==min(aic)))
}
p_max <- 24

AIC(treas3mo, p_max)
@

The optimal lag length for treas3mo is $p^* = 17$

<<fig = TRUE>>=
p_2yr <- AIC(treas2yr, p_max)
@

The optimal lag length for treas2yr is $p^* = 13$

<<fig = TRUE>>=
p_10yr <- AIC(treas10yr, p_max)
@

The optimal lag length for treas10yr is $p^* = 7$
\\[3mm]

{\bf 3.}
(a)\\[1mm]

We make a function that plots residuals for each of the time series.
<<>>=
residuals <- function (data, p){
  model <- ar(data, aic= FALSE, order = p, method ='ols')
  plot(model$resid)
  abline (h=0, col=2)   
}

p_3mo <- AIC(treas3mo, p_max)
p_2yr <- AIC(treas2yr, p_max)
p_2yr <- AIC(treas2yr, p_max)

@

<<fig=true>>=
residuals(treas3mo, p_3mo)
@

<<fig=true>>=
residuals(treas2yr, p_2yr)
@

<<fig=true>>=
residuals(treas10yr, p_10yr)
@
<<>>=
acf(treas3mo, type="partial")
acf(treas2yr, type="partial")
acf(treas10yr, type="partial")
@

For all three time series we can see that non of the residuals is autocorrelated. From the pictures we can see that in all three cases residuals are moving around value 0.  

(b)\\[1mm]

<<>>=
forecast <- function (data, p, n){
  model <- ar(data, aic= FALSE, order = p, method ='ols')
  forecast <- predict(model, n.ahead = n)
  return(as.vector(forecast$pred))  
}
forecast(treas3mo, p_3mo,12)
forecast(treas2yr, p_2yr,12)
forecast(treas10yr, p_10yr,12)

@



\clearpage

%%---------VIRI
http://en.wikipedia.org/wiki/Akaike_information_criterion

http://www.academia.edu/1426951/Akaike_Information_Criteria_Appication_to_Stationary_and_Nonstationary_Rainfalls_for_Wireless_Communication_Channel_in_Surabaya


\end{document}

